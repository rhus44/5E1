{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import sklearn.feature_extraction\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from skimage import measure, io\n",
    "from skimage import transform\n",
    "import train_r \n",
    "import skimage\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "\n",
    "save_results = r'C:\\Mosaic_Experiments'\n",
    "load_training = r'F:\\5E1\\Data_misc'\n",
    "\n",
    "# trainmospatches=np.load(os.path.join(load_training,'input_img_mos_patch.npy'))\n",
    "# trainpatches=np.load(os.path.join(load_training,'input_img_patch.npy'))\n",
    "\n",
    "# trainmospatches = (trainmospatches/255)*2 - 1\n",
    "# trainpatches = (trainpatches/255)*2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, UpSampling2D,Reshape\n",
    "from keras.optimizers import Adadelta, Nadam, RMSprop\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    20800     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 32)    2080      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 32)    25632     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 3)     2403      \n",
      "=================================================================\n",
      "Total params: 50,915\n",
      "Trainable params: 50,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1 = 64\n",
    "f2 = 32\n",
    "f3 = 32\n",
    "ff = 3\n",
    "k1 = (9,9)\n",
    "k2 = (1,1)\n",
    "k3 = (5,5)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(f1,k1, padding = 'same', input_shape=(None, None ,4), activation = 'relu'))\n",
    "\n",
    "model.add(UpSampling2D(size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(f2,k2, padding = 'same', activation='relu'))\n",
    "\n",
    "model.add(Conv2D(f3,k3, padding = 'same',activation = 'relu'))\n",
    "\n",
    "model.add(Conv2D(ff,k3, padding = 'same',activation = 'tanh'))\n",
    "\n",
    "\n",
    "#model.add(Reshape((64,64,3)))\n",
    "modsum = model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now=datetime.datetime.now()\n",
    "save_file=os.path.join(save_results,now.strftime(\"%Y-%m-%d %H-%M\"))\n",
    "os.mkdir(save_file)\n",
    "save_pred = os.path.join(save_file,'Epoch_Predictions')\n",
    "os.mkdir(save_pred)\n",
    "\n",
    "with open(os.path.join(save_file,'Model_Summary.txt'),'w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "    \n",
    "#rmsprop = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "optimizer_func = Nadam(lr=0.00002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "loss_func='mse'\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir=os.path.join(save_file,'TNSR_BRD'), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(os.path.join(save_file,'training.log'), separator=',', append=False)\n",
    "epoch_predict = train_r.Save_predictions(save_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer_func,loss=loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rhys\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Rhys\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Rhys\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 568, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "TypeError: 'function' object is not an iterator\n",
      "\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-de4f21d5b126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2009\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_r.train_seq(load_training,32,40)\n",
    "\n",
    "history = model.fit_generator(generator = train_r.train_seq.train_generator,steps_per_epoch=20)\n",
    "print(history.history)\n",
    "\n",
    "model.save(os.path.join(save_file,'DeMos_mod.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i6=np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\mos_npy\\kodim19.npy')\n",
    "g=i6[:,:,0]\n",
    "b=i6[:,:,1]\n",
    "r=i6[:,:,3]\n",
    "i62=np.stack((r,g,b),2)\n",
    "i62=i62.astype(np.float32)\n",
    "plt.imshow(i62)\n",
    "plt.show()\n",
    "pred1 = model.predict(np.array([i6]), batch_size=1)[0]\n",
    "print(pred1.shape)\n",
    "i7 = abs(pred1)\n",
    "plt.imshow(i7)\n",
    "plt.show()\n",
    "\n",
    "i8=np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\img_npy\\kodim19.npy')\n",
    "plt.imshow(i8)\n",
    "plt.show()\n",
    "\n",
    "i62=(transform.rescale(i62,(2,2))).astype(np.float32) \n",
    "\n",
    "slh=os.path.join(save_file,'lighthouse_images')\n",
    "os.mkdir(slh)\n",
    "\n",
    "skimage.io.imsave(os.path.join(slh,'input mosaiced.png'),i62)\n",
    "skimage.io.imsave(os.path.join(slh,'predicted.png'),i7)\n",
    "skimage.io.imsave(os.path.join(slh,'original.png'),i8)\n",
    "\n",
    "psnr_mos = measure.compare_psnr(i62,i8)\n",
    "print('Mosaiced and Interpolated PSNR: '+str(psnr_mos))\n",
    "\n",
    "psnr_pred = measure.compare_psnr(i7,i8)\n",
    "print('Predicted PSNR: '+str(psnr_pred))\n",
    "\n",
    "ssim= measure.compare_ssim(i7,i8,multichannel=True)\n",
    "print('Predicted SSIM: '+str(ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i6=np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\mos_npy\\kodim19.npy')\n",
    "g=i6[:,:,0]\n",
    "b=i6[:,:,1]\n",
    "r=i6[:,:,3]\n",
    "i62=np.stack((r,g,b),2)\n",
    "i62=i62.astype(np.float32)\n",
    "plt.imshow(i62)\n",
    "plt.show()\n",
    "pred1 = model.predict(np.array([i6]), batch_size=1)[0]\n",
    "print(pred1.shape)\n",
    "i7 = abs(pred1)\n",
    "plt.imshow(i7)\n",
    "plt.show()\n",
    "\n",
    "i8=np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\img_npy\\kodim19.npy')\n",
    "plt.imshow(i8)\n",
    "plt.show()\n",
    "\n",
    "i62=(transform.rescale(i62,(2,2))).astype(np.float32) \n",
    "\n",
    "slh=os.path.join(save_file,'lighthouse_images')\n",
    "os.mkdir(slh)\n",
    "\n",
    "skimage.io.imsave(os.path.join(slh,'input mosaiced.png'),i62)\n",
    "skimage.io.imsave(os.path.join(slh,'predicted.png'),i7)\n",
    "skimage.io.imsave(os.path.join(slh,'original.png'),i8)\n",
    "\n",
    "psnr_mos = measure.compare_psnr(i62,i8)\n",
    "print('Mosaiced and Interpolated PSNR: '+str(psnr_mos))\n",
    "\n",
    "psnr_pred = measure.compare_psnr(i7,i8)\n",
    "print('Predicted PSNR: '+str(psnr_pred))\n",
    "\n",
    "ssim= measure.compare_ssim(i7,i8,multichannel=True)\n",
    "print('Predicted SSIM: '+str(ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "k_orig = r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\img_lst'\n",
    "k_mos = r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\mos_lst'\n",
    "\n",
    "with open(k_orig, \"rb\") as fp1:   # Unpickling\n",
    "    k_or_imgs = pickle.load(fp1)\n",
    "    \n",
    "with open(k_mos, \"rb\") as fp2:   # Unpickling\n",
    "    k_mos_imgs = pickle.load(fp2)\n",
    "\n",
    "psnr = 0\n",
    "ssim = 0\n",
    "smpls=len(k_mos_imgs)\n",
    "for i in range(0,smpls):\n",
    "    pred_imgs = (model.predict(np.array([k_mos_imgs[i]]),batch_size=1)).astype(np.uint8)\n",
    "    orig_imgs = (k_or_imgs[i]).astype(np.uint8) \n",
    "    psnr = psnr + measure.compare_psnr(pred_imgs[0,:,:,:],orig_imgs)\n",
    "    ssim= ssim + measure.compare_ssim(pred_imgs[0,:,:,:],orig_imgs,multichannel=True)\n",
    "psnr_K_avg = psnr/smpls\n",
    "ssim_K_avg = ssim/smpls\n",
    "print('Kodak PSNR Average: '+str(psnr_K_avg))\n",
    "print('Kodak SSIM Average: '+str(ssim_K_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['Results'] = {\n",
    "    'McM PSNR':str(psnr_McM_avg),\n",
    "    'McM SSIM':str(ssim_McM_avg),\n",
    "    'Kodak PSNR':str(psnr_K_avg),\n",
    "    'Kodak SSIM':str(ssim_K_avg),\n",
    "}\n",
    "data['Parameters'] = {\n",
    "    'Loss Function': loss_func,\n",
    "    'Optimizer':str(type(optimizer_func))\n",
    "}\n",
    "data['Training Set'] = {\n",
    "    'Training Path': load_training,\n",
    "}\n",
    "\n",
    "with open(os.path.join(save_file,'results.txt'), 'w') as outfile:  \n",
    "    json.dump(data, outfile,indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'train_r' from 'C:\\\\mos_one\\\\Simple_DeMos_CNN\\\\train_r.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
