{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import sklearn.feature_extraction\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from skimage import measure, io\n",
    "from skimage import transform\n",
    "import train_r2 \n",
    "import skimage\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "\n",
    "save_results = r'C:\\Users\\buggyr\\Mosaic_Experiments\\models'\n",
    "load_training = r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\external\\Training Images 3'\n",
    "\n",
    "# trainmospatches=np.load(os.path.join(load_training,'input_img_mos_patch.npy'))\n",
    "# trainpatches=np.load(os.path.join(load_training,'input_img_patch.npy'))\n",
    "\n",
    "# trainmospatches = (trainmospatches/255)*2 - 1\n",
    "# trainpatches = (trainpatches/255)*2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, UpSampling2D,Reshape\n",
    "from keras.optimizers import Adadelta, Nadam, RMSprop\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    20800     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 32)    2080      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 32)    25632     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 3)     2403      \n",
      "=================================================================\n",
      "Total params: 50,915\n",
      "Trainable params: 50,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1 = 64\n",
    "f2 = 32\n",
    "f3 = 32\n",
    "ff = 3\n",
    "k1 = (9,9)\n",
    "k2 = (1,1)\n",
    "k3 = (5,5)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(f1,k1, padding = 'same', input_shape=(None, None ,4), activation = 'relu'))\n",
    "\n",
    "model.add(UpSampling2D(size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(f2,k2, padding = 'same', activation='relu'))\n",
    "\n",
    "model.add(Conv2D(f3,k3, padding = 'same',activation = 'relu'))\n",
    "\n",
    "model.add(Conv2D(ff,k3, padding = 'same',activation = 'tanh'))\n",
    "\n",
    "\n",
    "#model.add(Reshape((64,64,3)))\n",
    "modsum = model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, None, None, 64)    20800     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 32)    2080      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 32)    25632     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, None, 3)     2403      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, None, None, 3)     12        \n",
      "=================================================================\n",
      "Total params: 50,927\n",
      "Trainable params: 50,915\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f1 = 64\n",
    "f2 = 32\n",
    "f3 = 32\n",
    "ff = 3\n",
    "k1 = (9,9)\n",
    "k2 = (1,1)\n",
    "k3 = (5,5)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(f1,k1, padding = 'same', input_shape=(None, None ,4), activation = 'relu'))\n",
    "\n",
    "model.add(UpSampling2D(size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(f2,k2, padding = 'same', activation='relu'))\n",
    "\n",
    "model.add(Conv2D(f3,k3, padding = 'same',activation = 'relu'))\n",
    "\n",
    "model.add(Conv2D(ff,k3, padding = 'same',activation = 'tanh'))\n",
    "\n",
    "model.add(Conv2D(ff,1, padding = 'same', kernel_initializer=train_r2.yuv_init, \n",
    "                 input_shape = (None, None, 3), trainable = False))\n",
    "\n",
    "#model.add(Reshape((64,64,3)))\n",
    "modsum = model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now=datetime.datetime.now()\n",
    "save_file=os.path.join(save_results,now.strftime(\"%Y-%m-%d %H-%M\"))\n",
    "os.mkdir(save_file)\n",
    "save_pred = os.path.join(save_file,'Epoch_Predictions')\n",
    "os.mkdir(save_pred)\n",
    "\n",
    "with open(os.path.join(save_file,'Model_Summary.txt'),'w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "    \n",
    "#rmsprop = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "optimizer_func = Nadam(lr=0.00002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "loss_func='mse'\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir=os.path.join(save_file,'TNSR_BRD'), histogram_freq=0, write_graph=True, write_images=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(os.path.join(save_file,'training.log'), separator=',', append=False)\n",
    "epoch_predict = train_r2.Save_predictions(save_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer_func,loss=loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4106/4107 [============================>.] - ETA: 0s - loss: 3.9962e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float32 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4107/4107 [==============================] - 180s - loss: 4.0000e-04   \n",
      "Epoch 2/200\n",
      "4107/4107 [==============================] - 180s - loss: 3.7576e-04   \n",
      "Epoch 3/200\n",
      "4107/4107 [==============================] - 186s - loss: 3.5979e-04   \n",
      "Epoch 4/200\n",
      "4107/4107 [==============================] - 183s - loss: 3.4732e-04   \n",
      "Epoch 5/200\n",
      "4107/4107 [==============================] - 178s - loss: 3.3449e-04   \n",
      "Epoch 6/200\n",
      "4107/4107 [==============================] - 178s - loss: 3.2310e-04   \n",
      "Epoch 7/200\n",
      "4107/4107 [==============================] - 179s - loss: 3.1325e-04   \n",
      "Epoch 8/200\n",
      "4107/4107 [==============================] - 179s - loss: 3.0269e-04   \n",
      "Epoch 9/200\n",
      "4107/4107 [==============================] - 182s - loss: 2.9241e-04   \n",
      "Epoch 10/200\n",
      "4107/4107 [==============================] - 180s - loss: 2.9012e-04   \n",
      "Epoch 11/200\n",
      "4107/4107 [==============================] - 179s - loss: 2.8108e-04   \n",
      "Epoch 12/200\n",
      "4107/4107 [==============================] - 180s - loss: 2.7730e-04   \n",
      "Epoch 13/200\n",
      "4107/4107 [==============================] - 181s - loss: 2.6783e-04   \n",
      "Epoch 14/200\n",
      "4107/4107 [==============================] - 182s - loss: 2.6331e-04   \n",
      "Epoch 15/200\n",
      "4107/4107 [==============================] - 179s - loss: 2.5830e-04   \n",
      "Epoch 16/200\n",
      "4107/4107 [==============================] - 182s - loss: 2.5240e-04   \n",
      "Epoch 17/200\n",
      "4107/4107 [==============================] - 181s - loss: 2.4981e-04   \n",
      "Epoch 18/200\n",
      "4107/4107 [==============================] - 183s - loss: 2.4603e-04   \n",
      "Epoch 19/200\n",
      "3286/4107 [=======================>......] - ETA: 35s - loss: 2.2768e-04"
     ]
    }
   ],
   "source": [
    "#train_r.train_seq(load_training,32,40)\n",
    "fls = len(os.listdir(load_training))\n",
    "\n",
    "                            #train_dir, patch_size, batch_size\n",
    "train_generator = train_r2.train_generator_yuv(load_training,32,32)\n",
    "history = model.fit_generator(generator = train_generator,steps_per_epoch=3*fls,\n",
    "                             epochs = 200,callbacks = [tbCallBack,csv_logger,epoch_predict])\n",
    "print(history.history)\n",
    "\n",
    "model.save(os.path.join(save_file,'DeMos_mod.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4106/4107 [============================>.] - ETA: 0s - loss: 0.0069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float32 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4107/4107 [==============================] - 147s - loss: 0.0069   \n",
      "Epoch 2/100\n",
      "4107/4107 [==============================] - 174s - loss: 0.0049   \n",
      "Epoch 3/100\n",
      "4107/4107 [==============================] - 143s - loss: 0.0039   \n",
      "Epoch 4/100\n",
      "4107/4107 [==============================] - 146s - loss: 0.0032   \n",
      "Epoch 5/100\n",
      "4107/4107 [==============================] - 144s - loss: 0.0027   \n",
      "Epoch 6/100\n",
      "4107/4107 [==============================] - 142s - loss: 0.0023   \n",
      "Epoch 7/100\n",
      "4107/4107 [==============================] - 142s - loss: 0.0020   \n",
      "Epoch 8/100\n",
      "4107/4107 [==============================] - 142s - loss: 0.0018   \n",
      "Epoch 9/100\n",
      "4107/4107 [==============================] - 143s - loss: 0.0016   \n",
      "Epoch 10/100\n",
      "4107/4107 [==============================] - 142s - loss: 0.0015   \n",
      "Epoch 11/100\n",
      "4107/4107 [==============================] - 145s - loss: 0.0014   \n",
      "Epoch 12/100\n",
      "4107/4107 [==============================] - 142s - loss: 0.0013   \n",
      "Epoch 13/100\n",
      "4107/4107 [==============================] - 143s - loss: 0.0012   \n",
      "Epoch 14/100\n",
      "4107/4107 [==============================] - 143s - loss: 0.0011   \n",
      "Epoch 15/100\n",
      "4107/4107 [==============================] - 143s - loss: 0.0011   \n",
      "Epoch 16/100\n",
      "4107/4107 [==============================] - 143s - loss: 0.0010   \n",
      "Epoch 17/100\n",
      "4107/4107 [==============================] - 144s - loss: 9.8717e-04   \n",
      "Epoch 18/100\n",
      "4107/4107 [==============================] - 143s - loss: 9.4418e-04   \n",
      "Epoch 19/100\n",
      "3675/4107 [=========================>....] - ETA: 14s - loss: 8.4403e-04"
     ]
    }
   ],
   "source": [
    "ptch_sizes = [32, 64, 128]\n",
    "for ptch_size in ptch_sizes:\n",
    "    print(str(patch_size))\n",
    "    \n",
    "    now=datetime.datetime.now()\n",
    "    save_file=os.path.join(save_results,now.strftime(\"%Y-%m-%d %H-%M\"))\n",
    "    os.mkdir(save_file)\n",
    "    save_pred = os.path.join(save_file,'Epoch_Predictions')\n",
    "    os.mkdir(save_pred)\n",
    "\n",
    "    with open(os.path.join(save_file,'Model_Summary.txt'),'w') as fh:\n",
    "        # Pass the file handle in as a lambda function to make it callable\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "\n",
    "    #rmsprop = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    optimizer_func = Nadam(lr=0.00002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "    loss_func='mse'\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "    tbCallBack = keras.callbacks.TensorBoard(log_dir=os.path.join(save_file,'TNSR_BRD'), histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = keras.callbacks.CSVLogger(os.path.join(save_file,'training.log'), separator=',', append=False)\n",
    "    epoch_predict = train_r2.Save_predictions(save_pred)\n",
    "\n",
    "\n",
    "    model.compile(optimizer=optimizer_func,loss=loss_func)\n",
    "\n",
    "    #train_r.train_seq(load_training,32,40)\n",
    "    fls = len(os.listdir(load_training))\n",
    "\n",
    "                               #train_dir, patch_size, batch_size\n",
    "    train_generator = train_r2.train_generator2(load_training,patch_size,32)\n",
    "    history = model.fit_generator(generator = train_generator,steps_per_epoch=3*fls,\n",
    "                                 epochs = 100,callbacks = [tbCallBack,csv_logger,epoch_predict])\n",
    "\n",
    "    model.save(os.path.join(save_file,'DeMos_mod.h5'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i6=np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\mos_npy\\kodim19.npy')\n",
    "g=i6[:,:,0]\n",
    "b=i6[:,:,1]\n",
    "r=i6[:,:,3]\n",
    "i62=np.stack((r,g,b),2)\n",
    "i62=i62.astype(np.float32)\n",
    "plt.imshow(i62)\n",
    "plt.show()\n",
    "pred1 = model.predict(np.array([i6]), batch_size=1)[0]\n",
    "print(pred1.shape)\n",
    "i7 = abs(pred1)\n",
    "plt.imshow(i7)\n",
    "plt.show()\n",
    "\n",
    "i8=np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\img_npy\\kodim19.npy')\n",
    "plt.imshow(i8)\n",
    "plt.show()\n",
    "\n",
    "i62=(transform.rescale(i62,(2,2))).astype(np.float32) \n",
    "\n",
    "slh=os.path.join(save_file,'lighthouse_images')\n",
    "os.mkdir(slh)\n",
    "\n",
    "skimage.io.imsave(os.path.join(slh,'input mosaiced.png'),i62)\n",
    "skimage.io.imsave(os.path.join(slh,'predicted.png'),i7)\n",
    "skimage.io.imsave(os.path.join(slh,'original.png'),i8)\n",
    "\n",
    "psnr_mos = measure.compare_psnr(i62,i8)\n",
    "print('Mosaiced and Interpolated PSNR: '+str(psnr_mos))\n",
    "\n",
    "psnr_pred = measure.compare_psnr(i7,i8)\n",
    "print('Predicted PSNR: '+str(psnr_pred))\n",
    "\n",
    "ssim= measure.compare_ssim(i7,i8,multichannel=True)\n",
    "print('Predicted SSIM: '+str(ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i6=np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\mos_npy\\kodim19.npy')\n",
    "g=i6[:,:,0]\n",
    "b=i6[:,:,1]\n",
    "r=i6[:,:,3]\n",
    "i62=np.stack((r,g,b),2)\n",
    "i62=i62.astype(np.float32)\n",
    "plt.imshow(i62)\n",
    "plt.show()\n",
    "pred1 = model.predict(np.array([i6]), batch_size=1)[0]\n",
    "print(pred1.shape)\n",
    "i7 = abs(pred1)\n",
    "plt.imshow(i7)\n",
    "plt.show()\n",
    "\n",
    "i8=np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\img_npy\\kodim19.npy')\n",
    "plt.imshow(i8)\n",
    "plt.show()\n",
    "\n",
    "i62=(transform.rescale(i62,(2,2))).astype(np.float32) \n",
    "\n",
    "slh=os.path.join(save_file,'lighthouse_images')\n",
    "os.mkdir(slh)\n",
    "\n",
    "skimage.io.imsave(os.path.join(slh,'input mosaiced.png'),i62)\n",
    "skimage.io.imsave(os.path.join(slh,'predicted.png'),i7)\n",
    "skimage.io.imsave(os.path.join(slh,'original.png'),i8)\n",
    "\n",
    "psnr_mos = measure.compare_psnr(i62,i8)\n",
    "print('Mosaiced and Interpolated PSNR: '+str(psnr_mos))\n",
    "\n",
    "psnr_pred = measure.compare_psnr(i7,i8)\n",
    "print('Predicted PSNR: '+str(psnr_pred))\n",
    "\n",
    "ssim= measure.compare_ssim(i7,i8,multichannel=True)\n",
    "print('Predicted SSIM: '+str(ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "k_orig = r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\img_lst'\n",
    "k_mos = r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\mos_lst'\n",
    "\n",
    "with open(k_orig, \"rb\") as fp1:   # Unpickling\n",
    "    k_or_imgs = pickle.load(fp1)\n",
    "    \n",
    "with open(k_mos, \"rb\") as fp2:   # Unpickling\n",
    "    k_mos_imgs = pickle.load(fp2)\n",
    "\n",
    "psnr = 0\n",
    "ssim = 0\n",
    "smpls=len(k_mos_imgs)\n",
    "for i in range(0,smpls):\n",
    "    w = k_or_imgs[i].shape[0]\n",
    "    h = k_or_imgs[i].shape[1]\n",
    "    pred_imgs = (model.predict(np.array([k_mos_imgs[i]]),batch_size=1)).astype(np.uint8)\n",
    "    orig_imgs = (k_or_imgs[i]).astype(np.uint8) \n",
    "    \n",
    "    psnr = psnr + measure.compare_psnr(pred_imgs[i,5:h-5,5:w-5,:],orig_imgs[5:h-5,5:w-5,:])\n",
    "    ssim= ssim + measure.compare_ssim(pred_imgs[i,5:h-5,5:w-5,:],orig_imgs[5:h-5,5:w-5,:],multichannel=True)\n",
    "psnr_K_avg = psnr/smpls\n",
    "ssim_K_avg = ssim/smpls\n",
    "print('Kodak PSNR Average: '+str(psnr_K_avg))\n",
    "print('Kodak SSIM Average: '+str(ssim_K_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_imgs = (model.predict(np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\McM_test\\mos_npy\\sv.npy'), batch_size=1)).astype(np.uint8)\n",
    "orig_imgs = (np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\McM_test\\img_npy\\sv.npy')).astype(np.uint8)\n",
    "psnr=0\n",
    "smpls=orig_imgs.shape[0]\n",
    "for i in range(0,smpls):\n",
    "    psnr = psnr + measure.compare_psnr(pred_imgs[i,:,:,:],orig_imgs[i,:,:,:])\n",
    "    ssim= ssim + measure.compare_ssim(pred_imgs[i,:,:,:],orig_imgs[i,:,:,:],multichannel=True)\n",
    "    \n",
    "psnr_McM_avg = psnr/smpls\n",
    "ssim_McM_avg = ssim/smpls    \n",
    "print('McM PSNR Average: '+str(psnr/smpls))\n",
    "print('McM SSIM Average: '+str(ssim_McM_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['Results'] = {\n",
    "    'McM PSNR':str(psnr_McM_avg),\n",
    "    'McM SSIM':str(ssim_McM_avg),\n",
    "    'Kodak PSNR':str(psnr_K_avg),\n",
    "    'Kodak SSIM':str(ssim_K_avg),\n",
    "}\n",
    "data['Parameters'] = {\n",
    "    'Loss Function': loss_func,\n",
    "    'Optimizer':str(type(optimizer_func))\n",
    "}\n",
    "data['Training Set'] = {\n",
    "    'Training Path': load_training,\n",
    "}\n",
    "\n",
    "with open(os.path.join(save_file,'results.txt'), 'w') as outfile:  \n",
    "    json.dump(data, outfile,indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'train_r2' from 'C:\\\\Users\\\\buggyr\\\\Mosaic_Experiments\\\\src\\\\train_r2.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(train_r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "import train_r2\n",
    "\n",
    "train_generator_yuv = train_r2.train_generator_yuv(load_training,128,32)\n",
    "\n",
    "%prun next(train_generator_yuv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "im = cv2.imread(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\external\\Data_misc\\cat.jpg')\n",
    "img_ptch = train_r2.extractPatches(im,128) \n",
    "mos,orig = train_r2.mosaic(img_ptch)\n",
    "\n",
    "\n",
    "mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(cv2.cvtColor(orig[0], cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "plt.imshow(cv2.cvtColor(mos[0,:,:,1:], cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kodak_pth = r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\interim\\Kodak'\n",
    "predict_gen = train_r2.predict_generator2(kodak_pth)\n",
    "predk = predict_generator(predict_gen,steps = 24)\n",
    "orig = np.load(r'C:\\Users\\buggyr\\Mosaic_Experiments\\data\\processed\\Kodak_test\\img_npy')\n",
    "for i in range(predk[0]):\n",
    "    \n",
    "    psnr = psnr + measure.compare_psnr(pred_k[i,:,:,:],orig_imgs)\n",
    "    ssim= ssim + measure.compare_ssim(pred_imgs[0,:,:,:],orig_imgs,multichannel=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
